{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization, LSTM, Bidirectional, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
        "import time\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "QlrYokn2ldMG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TPUs in Colab\n",
        "https://colab.research.google.com/notebooks/tpu.ipynb#scrollTo=ovFDeMgtjqW4"
      ],
      "metadata": {
        "id": "97XMH7Uum_sP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "73kn_OaQma_b",
        "outputId": "4d4ef124-b126-4897-93eb-0c1bd013825a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.12.0\n",
            "Running on TPU  ['10.6.142.98:8470']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.6.142.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-faa1f5ca9bc1>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_connect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtpu_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py\u001b[0m in \u001b[0;36minitialize_tpu_system\u001b[0;34m(cluster_resolver)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu_system_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tpu_init_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m       \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m       raise errors.NotFoundError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36masync_wait\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m     \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_executors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36msync_executors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \"\"\"\n\u001b[1;32m    711\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m       \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextSyncExecutors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Context is not initialized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up TPU environment:"
      ],
      "metadata": {
        "id": "gNaSPGwjnKkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n"
      ],
      "metadata": {
        "id": "UDijS9BTmD9Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess data:"
      ],
      "metadata": {
        "id": "SV6WssHQncpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omwO_UgeovRZ",
        "outputId": "0b0bb896-cbf0-42c2-e15c-c135561127bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import shutil\n",
        "import gc\n",
        "import time\n",
        "from scipy.interpolate import interp1d"
      ],
      "metadata": {
        "id": "R40ipdkjdAYL"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolate_channels(eeg_data, target_channels):\n",
        "    current_channels = eeg_data.shape[0]\n",
        "    \n",
        "    if current_channels < target_channels:\n",
        "        # Generate the new channel indices\n",
        "        old_indices = np.linspace(0, current_channels - 1, current_channels)\n",
        "        new_indices = np.linspace(0, current_channels - 1, target_channels)\n",
        "\n",
        "        # Interpolate the data\n",
        "        interpolated_data = []\n",
        "        for i in range(eeg_data.shape[1]):\n",
        "            f = interp1d(old_indices, eeg_data[:, i], kind='cubic', fill_value='extrapolate')\n",
        "            interpolated_data.append(f(new_indices))\n",
        "\n",
        "        eeg_data = np.array(interpolated_data).T\n",
        "\n",
        "    return eeg_data\n"
      ],
      "metadata": {
        "id": "Q3PvU5NJGogb"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_subject_data(subject_id):\n",
        "    file_path = os.path.join(f'/content/drive/MyDrive/EEG_detection/EEG_data/subject_{subject_id:02d}.mat')\n",
        "    with h5py.File(file_path, 'r') as f:\n",
        "        eeg_data_struct = f['eeg_data']\n",
        "        labels_struct = f['labels']\n",
        "\n",
        "        # Access the 'filteredData' cell within the 'eeg_data' struct\n",
        "        eeg_data = eeg_data_struct['filteredData']\n",
        "        # print(eeg_data.shape)\n",
        "\n",
        "        # Access the 'sumLabel' cell within the 'labels' struct\n",
        "        labels = labels_struct['sumLabel']\n",
        "        # print(labels.shape)\n",
        "    \n",
        "        # Interpolate channels to have the same number (e.g., 26 channels)\n",
        "        eeg_data = interpolate_channels(eeg_data, 26)\n",
        "        print(\"interpolate: \", eeg_data.shape)\n",
        "\n",
        "    return eeg_data, labels\n",
        "\n",
        "\n",
        "def preprocess_data(eeg_data, labels):\n",
        "    window_size = 2 * 256  # 2 seconds * 256 samples per second\n",
        "    step_size = int(window_size * 0.25)  # 75% overlap\n",
        "\n",
        "    eeg_segments = []\n",
        "    label_segments = []\n",
        "\n",
        "    print(f\"EEG data shape: {eeg_data.shape}\")\n",
        "    print(f\"Labels shape: {labels.shape}\")\n",
        "\n",
        "    for i in range(0, eeg_data.shape[1] - window_size + 1, step_size):\n",
        "        eeg_segments.append(eeg_data[:, i:i + window_size])\n",
        "        label_segments.append(labels[:, i:i + window_size])\n",
        "\n",
        "    eeg_segments = np.array(eeg_segments)\n",
        "    label_segments = np.array(label_segments)\n",
        "\n",
        "    return eeg_segments, label_segments\n"
      ],
      "metadata": {
        "id": "EanAQ1HUncdX"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_subject15_data(subject_id):\n",
        "    file_path = (f'/content/drive/MyDrive/EEG_detection/闹心玩意/f_15.mat')\n",
        "    with h5py.File(file_path, 'r') as f:\n",
        "        eeg_data = f['filteredData']\n",
        "        labels = f['sumLabel']\n",
        "\n",
        "        print(eeg_data.shape)\n",
        "        # print(labels.shape)\n",
        "\n",
        "        # Interpolate channels to have the same number (e.g., 26 channels)\n",
        "        eeg_data = interpolate_channels(eeg_data, 26)\n",
        "        print(eeg_data.shape)\n",
        "\n",
        "    return eeg_data, labels\n",
        "\n",
        "print(f\"Processing subject {subject_id}...\")\n",
        "eeg_data_loaded, labels_loaded = load_subject15_data(subject_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Q9f0-X8zn4",
        "outputId": "66760421-b00b-41ba-b75c-aaf069cef547"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 24...\n",
            "(36873216, 26)\n",
            "(36873216, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = [5,6,7,8,9,10,11,12,13,14]"
      ],
      "metadata": {
        "id": "CfenHkoVrDXS"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "# Loop through all subjects and preprocess data\n",
        "for subject_id in range(2,25):\n",
        "    start_time = time.time()\n",
        "    print(f\"Processing subject {subject_id}...\")\n",
        "    if subject_id == 15:\n",
        "      eeg_data_loaded, labels_loaded = load_subject15_data(subject_id)\n",
        "    elif subject_id == 4:\n",
        "      continue\n",
        "    else:\n",
        "      eeg_data_loaded, labels_loaded = load_subject_data(subject_id)\n",
        "\n",
        "    # eeg_data, labels = preprocess_data(eeg_data_loaded, labels_loaded)\n",
        "\n",
        "    # # Save preprocessed data locally\n",
        "    # local_output_dir = '/content/preprocessed'\n",
        "    # if not os.path.exists(local_output_dir):\n",
        "    #     os.makedirs(local_output_dir)\n",
        "    \n",
        "    # dataset = tf.data.Dataset.from_tensor_slices((eeg_data, labels))\n",
        "    # tf.data.experimental.save(dataset, os.path.join(local_output_dir, f'dataset_subject_{subject_id}'))\n",
        "    # print(f\"Finished processing subject {subject_id}.\")\n",
        "\n",
        "    # # Copy the preprocessed data to Google Drive\n",
        "    # google_drive_output_dir = '/content/drive/MyDrive/EEG_detection/preprocessed'\n",
        "    # shutil.copytree(os.path.join(local_output_dir, f'dataset_subject_{subject_id}'), os.path.join(google_drive_output_dir, f'dataset_subject_{subject_id}'))\n",
        "\n",
        "    # elapsed_time = time.time() - start_time\n",
        "    # print(f\"Finished processing subject {subject_id} in {elapsed_time:.2f} seconds.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-sEEL0LeluH",
        "outputId": "40c26d8f-fc3a-44e0-941e-a57e5355f617"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 2...\n",
            "interpolate:  (32501504, 22)\n",
            "Processing subject 3...\n",
            "interpolate:  (35022336, 22)\n",
            "Processing subject 4...\n",
            "Processing subject 5...\n",
            "interpolate:  (35944960, 22)\n",
            "Processing subject 6...\n",
            "interpolate:  (61502976, 22)\n",
            "Processing subject 7...\n",
            "interpolate:  (61795328, 22)\n",
            "Processing subject 8...\n",
            "interpolate:  (18437888, 22)\n",
            "Processing subject 9...\n",
            "interpolate:  (62550528, 22)\n",
            "Processing subject 10...\n",
            "interpolate:  (46101504, 22)\n",
            "Processing subject 11...\n",
            "interpolate:  (32065792, 22)\n",
            "Processing subject 12...\n",
            "interpolate:  (19065856, 22)\n",
            "Processing subject 13...\n",
            "interpolate:  (30412800, 18)\n",
            "Processing subject 14...\n",
            "interpolate:  (23961600, 22)\n",
            "Processing subject 15...\n",
            "(36873216, 26)\n",
            "(36873216, 26)\n",
            "Processing subject 16...\n",
            "interpolate:  (17510400, 18)\n",
            "Processing subject 17...\n",
            "interpolate:  (19359744, 18)\n",
            "Processing subject 18...\n",
            "interpolate:  (32840960, 18)\n",
            "Processing subject 19...\n",
            "interpolate:  (27582976, 18)\n",
            "Processing subject 20...\n",
            "interpolate:  (25437696, 22)\n",
            "Processing subject 21...\n",
            "interpolate:  (30256384, 22)\n",
            "Processing subject 22...\n",
            "interpolate:  (28572416, 22)\n",
            "Processing subject 23...\n",
            "interpolate:  (24476160, 22)\n",
            "Processing subject 24...\n",
            "interpolate:  (19626752, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model:"
      ],
      "metadata": {
        "id": "Z-sYS27A3tLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape):\n",
        "    with strategy.scope():\n",
        "        model = Sequential([\n",
        "            Conv1D(16, kernel_size=5, activation='relu', input_shape=input_shape),\n",
        "            MaxPooling1D(pool_size=2),\n",
        "            BatchNormalization(),\n",
        "            Conv1D(32, kernel_size=5, activation='relu'),\n",
        "            MaxPooling1D(pool_size=2),\n",
        "            BatchNormalization(),\n",
        "            Conv1D(64, kernel_size=5, activation='relu'),\n",
        "            MaxPooling1D(pool_size=2),\n",
        "            BatchNormalization(),\n",
        "            LSTM(64, return_sequences=True),\n",
        "            Bidirectional(LSTM(64)),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "IodAA8NImI-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## compute metrics:"
      ],
      "metadata": {
        "id": "9yGnWz8-3yc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return sensitivity, specificity, accuracy\n",
        "\n",
        "def get_seizure_start_times(y_true, y_pred):\n",
        "    marked_seizures = np.where(np.diff(np.concatenate(([False], y_true, [False]))).astype(int) == 1)[0]\n",
        "    detected_seizures = np.where(np.diff(np.concatenate(([False], y_pred, [False]))).astype(int) == 1)[0]\n"
      ],
      "metadata": {
        "id": "o18S84QJ30Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "4q_Voh5Y311e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sequence the pipeline with batched training\n",
        "def train_and_evaluate_on_fold(fold, batch_size=4):\n",
        "    test_subject_ids = list(range(fold * 4 + 1, (fold + 1) * 4 + 1))\n",
        "    train_subject_ids = list(range(1, fold * 4 + 1)) + list(range((fold + 1) * 4 + 1, 25))\n",
        "\n",
        "    model = create_model(input_shape)\n",
        "\n",
        "    # Train the model in batches\n",
        "    for _ in range(10):  # 10 epochs\n",
        "        for i in range(0, len(train_subject_ids), batch_size):\n",
        "            batch_subject_ids = train_subject_ids[i:i + batch_size]\n",
        "            X_train_batch, y_train_batch = [], []\n",
        "\n",
        "            for subject_id in batch_subject_ids:\n",
        "                eeg_data, labels = load_subject_data(subject_id)\n",
        "                segments, segment_labels = preprocess_data(eeg_data, labels)\n",
        "                X_train_batch.append(segments)\n",
        "                y_train_batch.append(segment_labels)\n",
        "\n",
        "            X_train_batch = np.concatenate(X_train_batch, axis=0)\n",
        "            y_train_batch = np.concatenate(y_train_batch, axis=0)\n",
        "\n",
        "            model.train_on_batch(X_train_batch, y_train_batch)\n",
        "\n",
        "    # Evaluate the model\n",
        "    subjects_metrics = []\n",
        "    for subject_id in test_subject_ids:\n",
        "        eeg_data, labels = load_subject_data(subject_id)\n",
        "        segments, segment_labels = preprocess_data(eeg_data, labels)\n",
        "        X_test, y_test = segments, segment_labels\n",
        "\n",
        "        start_time = time.time()\n",
        "        y_pred_prob = model.predict(X_test)\n",
        "        processing_time = time.time() - start_time\n",
        "\n",
        "        y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n",
        "\n",
        "        sensitivity, specificity, accuracy = compute_metrics(y_test, y_pred)\n",
        "        roc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "        marked_seizures, detected_seizures = get_seizure_start_times(y_test, y_pred)\n",
        "        seizure_durations = [np.min(np.abs(marked - detected_seizures)) / 256 for marked in marked_seizures]\n",
        "        seizure_detection_time = np.mean(seizure_durations)\n",
        "\n",
        "        subjects_metrics.append((subject_id, sensitivity, specificity, accuracy, roc, len(marked_seizures), len(detected_seizures), seizure_detection_time, processing_time))\n",
        "\n",
        "    return subjects_metrics\n",
        "\n",
        "input_shape = (512, 16)  # 2 seconds * 256 samples/second, 16 channels\n",
        "\n",
        "all_subjects_metrics = []\n",
        "n_folds = 6\n",
        "\n",
        "for fold in range(n_folds):\n",
        "    print(f\"Training and evaluating model on fold {fold + 1}\")\n",
        "    subjects_metrics = train_and_evaluate_on_fold(fold)\n",
        "    all_subjects_metrics.extend(subjects_metrics)\n",
        "\n",
        "all_subjects_metrics.sort(key=lambda x: x[0])  # Sort the results by subject ID\n",
        "\n",
        "results_df = pd.DataFrame(all_subjects_metrics, columns=['Subject', 'Sensitivity', 'Specificity', 'Accuracy', 'ROC', 'Marked Seizures', 'Detected Seizures', 'Seizure Detection Time (s)', 'Processing Time (s)'])\n",
        "display(results_df)\n"
      ],
      "metadata": {
        "id": "373oewx935sn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}